{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e9ac54-678d-4450-92e5-38fdd4630eaa",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"200\" src=\"./img/northwestern.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fd192-542c-4d20-a27e-de09164005dd",
   "metadata": {},
   "source": [
    "# 5. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f592a4-a8e9-44f7-b1cc-87871de210c0",
   "metadata": {},
   "source": [
    "## Telling a story with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6547b-fb1e-45cd-be48-7a734e3ed326",
   "metadata": {},
   "source": [
    "There are thousands of entities listed in the report for the Named Entity Recognizer. Data includes names, dates, money, and locations. With the location data available it is possible to \"map\" the locations mentioned in the Northwestern Alumni News."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb31c5-4215-40ef-8612-edaafa4e3d66",
   "metadata": {},
   "source": [
    "Pandas is a tool that allows for working with csv tables. Since the Named Entity Recognizer is already a table, Pandas is a great tool to use for this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83baaeaf-febe-4a23-81f0-6f41076ddd0f",
   "metadata": {},
   "source": [
    "First, I downloaded the entities file from the HTRC and added it to a folder in this directory. I called this folder data and the file \"entities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57be89b-1139-4b7d-8048-7a54798ae865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code imports pandas and creates a dataframe based on the csv of entities. A dataframe is a Pandas table.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/entities.csv')\n",
    "# This displays the first ten lines only\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda942d5-e171-40f0-92e3-47bfd1c1bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are so many Pandas tools. Pandas is very worthwhile to learn. This function shows the mean value for the page_seq column, for example:\n",
    "df['page_seq'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168658c-f821-4dc1-b437-0e331670883a",
   "metadata": {},
   "source": [
    "Not terribly useful data right now, but it is great to explore the different functions offered by Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e645d90-6fc1-41a3-bfd4-ecb5b551d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am interested in doing something with the location data. I want to normalize the data a little before it is counted. I lowercase the entities here:\n",
    "df['entity'] = df['entity'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90366151-f536-4756-b6e3-bb3d18111ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This limits the dataframe to just displaying locations \n",
    "df2 = df[df['type'].str.match('LOCATION')]\n",
    "#I only want to see the top 100 locations, so this limits the result to the top 100 rows.\n",
    "df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699fe87-d244-42a0-aa6b-6f4a3462e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2['entity']\n",
    "#This counts the number of times each location is mentioned and sorts in descending order.\n",
    "df4 = df3.value_counts().head(100)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a221b-560d-4a22-8087-8e5419cc532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, in order to work with the data in Google Sheets it needs to be a csv\n",
    "df4.to_csv('./data/top-100-locations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045c894-952a-43ea-a696-7880d14cac29",
   "metadata": {},
   "source": [
    "I cleaned up the names of the locations in OpenRefine (HIGHLY recommend learning more about OpenRefine!). Once I did that, I added the cleaned up chart to Google Sheets. There is a built in mapping tool in Sheets, so all I had to do was insert a chart > map. Now, the top 100 locations mentioned in the Alumni magazine are mapped. The more a location is mentioned, the larger the size of the dot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42657dd6-4b38-4bc8-a8d2-60093c565ecc",
   "metadata": {},
   "source": [
    "![locations mentioned in the collection](./img/map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb93d9d-bb04-4ca2-96d3-b5a431d01e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
